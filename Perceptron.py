"""
The Perceptron Algorithm:
    1 - For every input, multply that input by its weight;
    2 - Sum all of the weighted inputs;
    3 - Compute the output of the perceptron based on that sum passed through an activation function (the sign function)
"""
import random
#The Activation Function
def sign(pred):
    """
    pred: int -> Generally 1 or 0 classifying the prediction.

    returns: int -> the classification defined by the defined rule and the sum generated by the perceptron weights.
    """
    try:
        if pred > 0:
            return 1
        else:
            return 0
    except ValueError:
        print('Input is not a number')

#PERCEPTRON
class Perceptron:
    """
    n: int -> number of dimensions;
    lr: float -> learning rate.

    Perceptron object with all its data and methods for training and predicting.
    """

    def __init__(self, n, lr):
        self.n = n
        self.lr = lr
        self.weights = []
        #Initialize the weights randomly
        for i in range(0, n):
            self.weights[i] = random.random()
    
    #METHOD TO TRAIN THE PERCEPTRON
    #Training simply means updating the weights accordingly
    #to the error coming from the predictions made on the
    #training data
    def train(self,inputs,target):
        """
        inputs: [] -> array with the data associated with each data point;
        target: int -> Generally 1 or 0 classifying the prediction.

        returns: None -> It updates the objects's weights.
        """
        guess = self.predict(inputs)
        #possible errors -> -1-(-1) = 0; -1-(1) = -2; 1-(-1) = 2; 1-(1) = 0 
        error = target - guess
        #Tune all the weights Gradient Descent style
        for i in range(0, len(self.weights)):
            #if error = 0, weight doesn't get updated
            #the weights and the respective dimension is linked by the indices in both arrays
            self.weights[i] = error*inputs[i]*self.lr
    
    def predict(self,inputs):
        """
         inputs: [] -> array with the data associated with each data point.

         return: int -> the value returned by the activation function.
        """
        sum = 0
        for i in range(0,len(self.weights)):
            sum += inputs[i]*self.weights[i]
        
        return sign(sum)
    
    #Get the weights
    def getWeights(self):
        """
        return: [] -> current weights for the perceptron.
        """
        return self.weights
    #Set Learning rate
    def setWeights(self, newWeights):
        """
        newWeights: [] -> array with the new weight values in the same ordered as the targeted dimensions.

        return: None
        """
        self.weights = newWeights
    #Get the weights
    def getLr(self):
        """
        return: float -> current learning rate for the perceptron.
        """
        return self.lr
    #Set Learning rate
    def setLearning(self,lRate):
        """
        lRate: float -> new learning rate value.
        return: None
        """
        self.lr = lRate
    
    def __str__(self):
        return f'Perceptron Object -> Weights:({self.weights}, Learning Rate: {self.lr})'
